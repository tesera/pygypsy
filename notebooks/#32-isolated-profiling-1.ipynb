{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial attemps at profiling had very confusing results; possibly because of module loading and i/o\n",
    "\n",
    "Here, gypsy will be run and profiled on one plot, with no module loading/io recorded in profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characterize what is happening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In several places, we append data to a data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../gypsy/GYPSYNonSpatial.py:1028:        densities_along_time.append({'N_bh_AwT': N_bh_AwT, 'N_bh_SwT': N_bh_SwT, 'N_bh_SbT': N_bh_SbT, 'N_bh_PlT': N_bh_PlT,\n",
      "../gypsy/GYPSYNonSpatial.py:1163:            BA_Aw_DF = BA_Aw_DF.append({'BA_Aw':BA_AwB}, ignore_index=True)\n",
      "../gypsy/GYPSYNonSpatial.py:1287:            BA_Sb_DF = BA_Sb_DF.append({'BA_Sb': BA_SbB}, ignore_index=True)\n",
      "../gypsy/GYPSYNonSpatial.py:1422:            BA_Sw_DF = BA_Sw_DF.append({'BA_Sw': BA_SwB}, ignore_index=True)\n",
      "../gypsy/GYPSYNonSpatial.py:1673:            BA_Pl_DF = BA_Pl_DF.append({'BA_Pl': BA_PlB}, ignore_index=True)\n",
      "../gypsy/forward_simulation.py:367:            output_DF_Sw = output_DF_Sw.append({'BA_Sw':BA_SwT}, ignore_index=True)\n",
      "../gypsy/forward_simulation.py:368:            output_DF_Sb = output_DF_Sb.append({'BA_Sb':BA_SbT}, ignore_index=True)\n",
      "../gypsy/forward_simulation.py:369:            output_DF_Pl = output_DF_Pl.append({'BA_Pl':BA_PlT}, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "grep --colour -nr append ../gypsy/*.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Either in the way we do it, or by its nature, it is a slow operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method append in module pandas.core.frame:\n",
      "\n",
      "append(self, other, ignore_index=False, verify_integrity=False) unbound pandas.core.frame.DataFrame method\n",
      "    Append rows of `other` to the end of this frame, returning a new\n",
      "    object. Columns not in this frame are added as new columns.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    other : DataFrame or Series/dict-like object, or list of these\n",
      "        The data to append.\n",
      "    ignore_index : boolean, default False\n",
      "        If True, do not use the index labels.\n",
      "    verify_integrity : boolean, default False\n",
      "        If True, raise ValueError on creating index with duplicates.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    appended : DataFrame\n",
      "    \n",
      "    Notes\n",
      "    -----\n",
      "    If a list of dict/series is passed and the keys are all contained in\n",
      "    the DataFrame's index, the order of the columns in the resulting\n",
      "    DataFrame will be unchanged.\n",
      "    \n",
      "    See also\n",
      "    --------\n",
      "    pandas.concat : General function to concatenate DataFrame, Series\n",
      "        or Panel objects\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    \n",
      "    >>> df = pd.DataFrame([[1, 2], [3, 4]], columns=list('AB'))\n",
      "    >>> df\n",
      "       A  B\n",
      "    0  1  2\n",
      "    1  3  4\n",
      "    >>> df2 = pd.DataFrame([[5, 6], [7, 8]], columns=list('AB'))\n",
      "    >>> df.append(df2)\n",
      "       A  B\n",
      "    0  1  2\n",
      "    1  3  4\n",
      "    0  5  6\n",
      "    1  7  8\n",
      "    \n",
      "    With `ignore_index` set to True:\n",
      "    \n",
      "    >>> df.append(df2, ignore_index=True)\n",
      "       A  B\n",
      "    0  1  2\n",
      "    1  3  4\n",
      "    2  5  6\n",
      "    3  7  8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(pd.DataFrame.append)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is nothing very clear about performance from the documentation. It may be worth examining the source, and of course googling append performance.\n",
    "\n",
    "python - Improve Row Append Performance On Pandas DataFrames - Stack Overflow  \n",
    "http://stackoverflow.com/questions/27929472/improve-row-append-performance-on-pandas-dataframes\n",
    "\n",
    "python - Pandas: Why should appending to a dataframe of floats and ints be slower than if its full of NaN - Stack Overflow  \n",
    "http://stackoverflow.com/questions/17141828/pandas-why-should-appending-to-a-dataframe-of-floats-and-ints-be-slower-than-if\n",
    "\n",
    "python - Creating large Pandas DataFrames: preallocation vs append vs concat - Stack Overflow  \n",
    "http://stackoverflow.com/questions/31690076/creating-large-pandas-dataframes-preallocation-vs-append-vs-concat\n",
    "\n",
    "python - efficient appending to pandas dataframes - Stack Overflow  \n",
    "http://stackoverflow.com/questions/32746248/efficient-appending-to-pandas-dataframes\n",
    "\n",
    "python - Pandas append perfomance concat/append using \"larger\" DataFrames - Stack Overflow  \n",
    "http://stackoverflow.com/questions/31860671/pandas-append-perfomance-concat-append-using-larger-dataframes\n",
    "\n",
    "pandas.DataFrame.append â€” pandas 0.18.1 documentation  \n",
    "http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.append.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decide on the action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not append in a loop. It makes a copy each time and the memory allocation is poor. Should have known; it's interesting to see it demonstrated in the wild!\n",
    "\n",
    "Pre-allocate the dataframe length by giving it an index and assigning to the index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MWE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 1.39 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "d = pd.DataFrame(columns=['A'])\n",
    "for i in xrange(1000):\n",
    "    d.append({'A': i}, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 150 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "d = pd.DataFrame(columns=['A'], index=xrange(1000))\n",
    "for i in xrange(1000):\n",
    "    d.loc[i,'A'] = i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.266666666666666"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.39/.150"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speedup of nearly 1 order of magnitude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revise the code\n",
    "\n",
    "Go on. Do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review code changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acdd1d2 Finish factoring append out of all operations\n",
      "a071b77 Add notebook for first iteration of optimizing\n",
      "78ff930 Start factoring append out of simulation loop\n",
      "e0c1fbc Remove a concat operation\n",
      "fe82864 Update tests to use allclose\n",
      "f13d6c6 fixups\n",
      "f90e48a Preallocate pl data frame for basal area\n",
      "d7de2f3 Preallocate dataframes for bafromzero aw, sb, sw\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "git log --since 2016-11-07 --oneline | head -n 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mdiff --git a/gypsy/GYPSYNonSpatial.py b/gypsy/GYPSYNonSpatial.py\u001b[m\r\n",
      "\u001b[1mindex 35f67d3..24ec050 100644\u001b[m\r\n",
      "\u001b[1m--- a/gypsy/GYPSYNonSpatial.py\u001b[m\r\n",
      "\u001b[1m+++ b/gypsy/GYPSYNonSpatial.py\u001b[m\r\n",
      "\u001b[36m@@ -984,7 +984,7 @@\u001b[m \u001b[mdef BAfromZeroToDataAw(startTage, SI_bh_Aw, N0_Aw, BA_Aw0, SDF_Aw0, f_Aw,\u001b[m\r\n",
      "     basal_area_aw_df = pd.DataFrame(columns=['BA_Aw'], index=xrange(max_age))\u001b[m\r\n",
      "     BA_tempAw = BA_Aw0\u001b[m\r\n",
      " \u001b[m\r\n",
      "\u001b[31m-    for SC_Dict, i in enumerate(densities[0: max_age]):\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m    for i, SC_Dict in enumerate(densities[0: max_age]):\u001b[m\r\n",
      "         bhage_Aw = SC_Dict['bhage_Aw']\u001b[m\r\n",
      "         SC_Aw = SC_Dict['SC_Aw']\u001b[m\r\n",
      "         N_bh_AwT = SC_Dict['N_bh_AwT']\u001b[m\r\n",
      "\u001b[36m@@ -1132,7 +1132,7 @@\u001b[m \u001b[mdef BAfromZeroToDataSb(startTage, startTageSb, y2bh_Sb, SC_Sb, SI_bh_Sb,\u001b[m\r\n",
      "         t += 1\u001b[m\r\n",
      "         startTageSb += 1\u001b[m\r\n",
      " \u001b[m\r\n",
      "\u001b[31m-    return BA_SbB, BA_Sb_DF\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m    return BA_SbB, basal_area_sb_df\u001b[m\r\n",
      " \u001b[m\r\n",
      " \u001b[m\r\n",
      " def BAfactorFinder_Sw(**kwargs):\u001b[m\r\n",
      "\u001b[36m@@ -1263,7 +1263,7 @@\u001b[m \u001b[mdef BAfromZeroToDataSw(startTage, startTageSw, y2bh_Sw, SC_Sw, SI_bh_Sw,\u001b[m\r\n",
      "         t += 1\u001b[m\r\n",
      "         startTageSw += 1\u001b[m\r\n",
      " \u001b[m\r\n",
      "\u001b[31m-    return BA_SwB, BA_Sw_DF\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m    return BA_SwB, basal_area_sw_df\u001b[m\r\n",
      " \u001b[m\r\n",
      " \u001b[m\r\n",
      " def BAfactorFinder_Pl(**kwargs):\u001b[m\r\n",
      "\u001b[36m@@ -1366,7 +1366,7 @@\u001b[m \u001b[mdef BAfromZeroToDataPl(startTage, startTagePl, y2bh_Pl, SC_Pl, SI_bh_Pl,\u001b[m\r\n",
      "     elif simulation_choice == 'no':\u001b[m\r\n",
      "         max_age = 250\u001b[m\r\n",
      " \u001b[m\r\n",
      "\u001b[31m-    BA_Pl_DF = pd.DataFrame(columns=['BA_Pl'])\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m    basal_area_pl_df = pd.DataFrame(columns=['BA_Pl'], index=xrange(max_age))\u001b[m\r\n",
      "     t = 0\u001b[m\r\n",
      "     BA_tempPl = BA_Pl0\u001b[m\r\n",
      " \u001b[m\r\n",
      "\u001b[36m@@ -1390,12 +1390,12 @@\u001b[m \u001b[mdef BAfromZeroToDataPl(startTage, startTagePl, y2bh_Pl, SC_Pl, SI_bh_Pl,\u001b[m\r\n",
      "             BA_PlB = 0\u001b[m\r\n",
      " \u001b[m\r\n",
      "         if simulation == False:\u001b[m\r\n",
      "\u001b[31m-            BA_Pl_DF = BA_Pl_DF.append({'BA_Pl': BA_PlB}, ignore_index=True)\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m            basal_area_pl_df.loc[t, 'BA_Pl'] = BA_PlB\u001b[m\r\n",
      " \u001b[m\r\n",
      "         t += 1\u001b[m\r\n",
      "         startTagePl += 1\u001b[m\r\n",
      " \u001b[m\r\n",
      "\u001b[31m-    return BA_PlB, BA_Pl_DF\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m    return BA_PlB, basal_area_pl_df\u001b[m\r\n",
      " \u001b[m\r\n",
      " \u001b[m\r\n",
      " def GrossTotalVolume_Aw(BA_Aw, topHeight_Aw):\u001b[m\r\n",
      "\u001b[1mdiff --git a/gypsy/forward_simulation.py b/gypsy/forward_simulation.py\u001b[m\r\n",
      "\u001b[1mindex 530cbad..60b1320 100644\u001b[m\r\n",
      "\u001b[1m--- a/gypsy/forward_simulation.py\u001b[m\r\n",
      "\u001b[1m+++ b/gypsy/forward_simulation.py\u001b[m\r\n",
      "\u001b[36m@@ -5,31 +5,34 @@\u001b[m \u001b[mCreated on Fri Apr 29 16:06:29 2016\u001b[m\r\n",
      " @author: juliannosambatti\u001b[m\r\n",
      " \"\"\"\u001b[m\r\n",
      " import logging\u001b[m\r\n",
      "\u001b[31m-import pandas as pd\u001b[m\r\n",
      " import datetime\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32mimport numpy as np\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32mimport pandas as pd\u001b[m\r\n",
      " \u001b[m\r\n",
      " from utils import _log_loop_progress\u001b[m\r\n",
      "\u001b[31m-from GYPSYNonSpatial import (BasalAreaIncrementNonSpatialSw,\u001b[m\r\n",
      "\u001b[31m-                             BasalAreaIncrementNonSpatialSb,\u001b[m\r\n",
      "\u001b[31m-                             BasalAreaIncrementNonSpatialPl,\u001b[m\r\n",
      "\u001b[31m-                             SCestimate,\u001b[m\r\n",
      "\u001b[31m-                             BAfactorFinder_Aw,\u001b[m\r\n",
      "\u001b[31m-                             BAfromZeroToDataAw,\u001b[m\r\n",
      "\u001b[31m-                             BAfactorFinder_Sb,\u001b[m\r\n",
      "\u001b[31m-                             BAfromZeroToDataSb,\u001b[m\r\n",
      "\u001b[31m-                             BAfactorFinder_Sw,\u001b[m\r\n",
      "\u001b[31m-                             BAfromZeroToDataSw,\u001b[m\r\n",
      "\u001b[31m-                             BAfactorFinder_Pl,\u001b[m\r\n",
      "\u001b[31m-                             BAfromZeroToDataPl,\u001b[m\r\n",
      "\u001b[31m-                             MerchantableVolumeAw,\u001b[m\r\n",
      "\u001b[31m-                             MerchantableVolumeSw,\u001b[m\r\n",
      "\u001b[31m-                             MerchantableVolumeSb,\u001b[m\r\n",
      "\u001b[31m-                             MerchantableVolumePl,\u001b[m\r\n",
      "\u001b[31m-                             densities_and_SCs_to_250,\u001b[m\r\n",
      "\u001b[31m-                             GrossTotalVolume_Aw,\u001b[m\r\n",
      "\u001b[31m-                             GrossTotalVolume_Sw,\u001b[m\r\n",
      "\u001b[31m-                             GrossTotalVolume_Sb,\u001b[m\r\n",
      "\u001b[31m-                             GrossTotalVolume_Pl)\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32mfrom GYPSYNonSpatial import (\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m    BasalAreaIncrementNonSpatialSw,\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m    BasalAreaIncrementNonSpatialSb,\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m    BasalAreaIncrementNonSpatialPl,\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m    SCestimate,\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m    BAfactorFinder_Aw,\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m    BAfromZeroToDataAw,\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m    BAfactorFinder_Sb,\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m    BAfromZeroToDataSb,\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m    BAfactorFinder_Sw,\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m    BAfromZeroToDataSw,\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m    BAfactorFinder_Pl,\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m    BAfromZeroToDataPl,\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m    MerchantableVolumeAw,\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m    MerchantableVolumeSw,\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m    MerchantableVolumeSb,\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m    MerchantableVolumePl,\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m    densities_and_SCs_to_250,\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m    GrossTotalVolume_Aw,\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m    GrossTotalVolume_Sw,\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m    GrossTotalVolume_Sb,\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m    GrossTotalVolume_Pl\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m)\u001b[m\r\n",
      " \u001b[m\r\n",
      " logger = logging.getLogger(__name__)\u001b[m\r\n",
      " \u001b[m\r\n",
      "\u001b[36m@@ -289,11 +292,6 @@\u001b[m \u001b[mdef simulate_forwards_df(plot_df, simulation_choice='yes'):\u001b[m\r\n",
      "             densities=densities,\u001b[m\r\n",
      "             printWarnings=True)\u001b[m\r\n",
      " \u001b[m\r\n",
      "\u001b[31m-        output_DF_Aw = pd.DataFrame(columns=['BA_Aw'])\u001b[m\r\n",
      "\u001b[31m-        output_DF_Sw = pd.DataFrame(columns=['BA_Sw'])\u001b[m\r\n",
      "\u001b[31m-        output_DF_Sb = pd.DataFrame(columns=['BA_Sb'])\u001b[m\r\n",
      "\u001b[31m-        output_DF_Pl = pd.DataFrame(columns=['BA_Pl'])\u001b[m\r\n",
      "\u001b[31m-\u001b[m\r\n",
      "         f_Aw = species_factors['f_Aw']\u001b[m\r\n",
      "         f_Sw = species_factors['f_Sw']\u001b[m\r\n",
      "         f_Sb = species_factors['f_Sb']\u001b[m\r\n",
      "\u001b[36m@@ -313,18 +311,33 @@\u001b[m \u001b[mdef simulate_forwards_df(plot_df, simulation_choice='yes'):\u001b[m\r\n",
      "         BA_0_to_data_Sw = BAfromZeroToDataSw(startTage, startTageSw, y2bh_Sw, SC_Sw, SI_bh_Sw, N_bh_SwT, N0_Sw, SDF_Aw0, SDF_Pl0, SDF_Sb0, BA_Sw0, f_Sw, simulation_choice, simulation=False)\u001b[m\r\n",
      "         BA_0_to_data_Pl = BAfromZeroToDataPl(startTage, startTagePl, y2bh_Pl, SC_Pl, SI_bh_Pl, N_bh_PlT, N0_Pl, SDF_Aw0, SDF_Sw0, SDF_Sb0, BA_Pl0, f_Pl, simulation_choice, simulation=False)\u001b[m\r\n",
      " \u001b[m\r\n",
      "\u001b[31m-        output_DF_Aw = pd.concat([BA_0_to_data_Aw[1]], axis=1)\u001b[m\r\n",
      "\u001b[31m-        output_DF_Sw = pd.concat([BA_0_to_data_Sw[1]], axis=1)\u001b[m\r\n",
      "\u001b[31m-        output_DF_Sb = pd.concat([BA_0_to_data_Sb[1]], axis=1)\u001b[m\r\n",
      "\u001b[31m-        output_DF_Pl = pd.concat([BA_0_to_data_Pl[1]], axis=1)\u001b[m\r\n",
      "\u001b[31m-\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m        output_DF_Aw = BA_0_to_data_Aw[1]\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m        output_DF_Sw = BA_0_to_data_Sw[1]\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m        output_DF_Sb = BA_0_to_data_Sb[1]\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m        output_DF_Pl = BA_0_to_data_Pl[1]\u001b[m\r\n",
      "         if simulation_choice == 'no':\u001b[m\r\n",
      "             continue\u001b[m\r\n",
      " \u001b[m\r\n",
      "\u001b[31m-        '''simulating growth forwards in time starting from the time at which data was taken '''\u001b[m\r\n",
      "\u001b[31m-        t = startTage\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m        # allocate extra space for the simulation results\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m        # this is not ideal, would rather follow what is done for aspen, but at least\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m        # this only appends once instead of for every year in the iteration\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m        # TODO: fill with NaN instead of 0s?\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m        n_extra_rows = len(densities)-startTage+1\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m        output_DF_Sb = pd.concat([\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m            output_DF_Sb,\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m            pd.DataFrame({'BA_Sb': [np.NaN]*n_extra_rows})\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m        ], axis=0, ignore_index=True)\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m        output_DF_Sw = pd.concat([\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m            output_DF_Sw,\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m            pd.DataFrame({'BA_Sw': [np.NaN]*n_extra_rows})\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m        ], axis=0, ignore_index=True)\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m        output_DF_Pl = pd.concat([\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m            output_DF_Pl,\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m            pd.DataFrame({'BA_Pl': [np.NaN]*n_extra_rows})\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m        ], axis=0, ignore_index=True)\u001b[m\r\n",
      " \u001b[m\r\n",
      "         logger.debug('Starting main simulation')\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m        t = startTage\u001b[m\r\n",
      "         for SC_Dict in densities[t-1:]:\u001b[m\r\n",
      "             bhage_SwF = SC_Dict['bhage_Sw']\u001b[m\r\n",
      "             SC_SwF = SC_Dict['SC_Sw']\u001b[m\r\n",
      "\u001b[36m@@ -341,7 +354,7 @@\u001b[m \u001b[mdef simulate_forwards_df(plot_df, simulation_choice='yes'):\u001b[m\r\n",
      "             logger.debug('Simulating year %d', t)\u001b[m\r\n",
      " \u001b[m\r\n",
      " \u001b[m\r\n",
      "\u001b[31m-\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m            # TODO: it looks like Aw was factored out of here, these species should have that done also\u001b[m\r\n",
      "             if N_bh_SbT > 0:\u001b[m\r\n",
      "                 BA_SbT = BA_SbT + BasalAreaIncrementNonSpatialSb('Sb', SC_SbF, SI_bh_Sb, N_bh_SbT, N0_Sb, bhage_SbF, BA_SbT)\u001b[m\r\n",
      "                 if BA_SbT < 0:\u001b[m\r\n",
      "\u001b[36m@@ -363,10 +376,10 @@\u001b[m \u001b[mdef simulate_forwards_df(plot_df, simulation_choice='yes'):\u001b[m\r\n",
      "             else:\u001b[m\r\n",
      "                 BA_PlT = 0\u001b[m\r\n",
      " \u001b[m\r\n",
      "\u001b[31m-\u001b[m\r\n",
      "\u001b[31m-            output_DF_Sw = output_DF_Sw.append({'BA_Sw':BA_SwT}, ignore_index=True)\u001b[m\r\n",
      "\u001b[31m-            output_DF_Sb = output_DF_Sb.append({'BA_Sb':BA_SbT}, ignore_index=True)\u001b[m\r\n",
      "\u001b[31m-            output_DF_Pl = output_DF_Pl.append({'BA_Pl':BA_PlT}, ignore_index=True)\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m            # TODO: should these be t+1?\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m            output_DF_Sw.loc[t, 'BA_Sw'] = BA_SwT\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m            output_DF_Sb.loc[t, 'BA_Sb'] = BA_SbT\u001b[m\r\n",
      "\u001b[32m+\u001b[m\u001b[32m            output_DF_Pl.loc[t, 'BA_Pl'] = BA_PlT\u001b[m\r\n",
      " \u001b[m\r\n",
      "             t += 1\u001b[m\r\n",
      "             startTageAwF += 1\u001b[m\r\n",
      "\u001b[36m@@ -379,7 +392,6 @@\u001b[m \u001b[mdef simulate_forwards_df(plot_df, simulation_choice='yes'):\u001b[m\r\n",
      "             [densities_DF, output_DF_Aw, output_DF_Sw, output_DF_Sb, output_DF_Pl],\u001b[m\r\n",
      "             axis=1\u001b[m\r\n",
      "         )\u001b[m\r\n",
      "\u001b[31m-\u001b[m\r\n",
      "         #http://stackoverflow.com/questions/25314547/cell-var-from-loop-warning-from-pylint\u001b[m\r\n",
      " \u001b[m\r\n",
      "         output_DF['Gross_Total_Volume_Aw'] = output_DF.apply(\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "! git diff HEAD~7 ../gypsy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests\n",
    "\n",
    "There are some issues with the tests - the data does not match the old output data to within 3 or even 2 decimal places. The mismatch is always:\n",
    "\n",
    "`(mismatch 0.221052631579%)`\n",
    "\n",
    "It was resolved in fe82864:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fe82864 Update tests to use allclose\n"
     ]
    }
   ],
   "source": [
    "%%bash \n",
    "git log --since '2016-11-08' --oneline | grep tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/gypsy/venv/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "from gypsy.forward_simulation import simulate_forwards_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../private-data/prepped_random_sample_300.csv', index_col=0, nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "*** Profile stats marshalled to file u'forward-sim-1.prof'. \n",
      "\n",
      "*** Profile printout saved to text file u'forward-sim-1.txt'. \n"
     ]
    }
   ],
   "source": [
    "%%prun -D forward-sim-1.prof -T forward-sim-1.txt -q\n",
    "result = simulate_forwards_df(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         10055657 function calls (9875729 primitive calls) in 76.264 seconds\r\n",
      "\r\n",
      "   Ordered by: internal time\r\n",
      "\r\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n",
      "   492069    6.857    0.000    6.857    0.000 GYPSYNonSpatial.py:427(BasalAreaIncrementNonSpatialAw)\r\n",
      "  1836602    6.527    0.000    9.190    0.000 {isinstance}\r\n",
      "796652/624746    3.102    0.000    4.823    0.000 {len}\r\n",
      "     7191    2.670    0.000   40.459    0.006 GYPSYNonSpatial.py:959(BAfromZeroToDataAw)\r\n",
      "   511948    2.020    0.000    3.373    0.000 {getattr}\r\n"
     ]
    }
   ],
   "source": [
    "!head forward-sim-1.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff: forward-sim.txt: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!diff -y forward-sim-1.txt forward-sim.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare performance visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use either of these commands to visualize the profiling\n",
    "\n",
    "```\n",
    "pyprof2calltree -k -i forward-sim-1.prof forward-sim-1.txt\n",
    "\n",
    "# or\n",
    "\n",
    "dc run --service-ports snakeviz notebooks/forward-sim-1.prof\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![definitive reference profile screenshot](forward-sim-performance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### New"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1st iteration performance](forward-sim-1-performance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of performance improvements\n",
    "\n",
    "forward_simulation is now 4x faster due to the changes outlined in the code review section above\n",
    "\n",
    "on my hardware, this takes 1000 plots to ~8 minutes\n",
    "\n",
    "on carol's hardware, this takes 1000 plots to ~25 minutes\n",
    "\n",
    "For 1 million plots, we're looking at 5 to 17 days on desktop hardware\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caveat\n",
    "\n",
    "- this isn't dealing with i/o. reading the plot table in is not a huge problem, especially if we declare the field types, but writing the growth curves for each plot will be time consuming. threads may be necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify new areas to optimize\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- need to find another order of magnitude improvement to get to 2.4-15 hours \n",
    "  - pandas indexing `.ix` (get and set item) is taking 6 and 19% respectively\n",
    "  - collectively, the lambdas being applied to output data frame are taking 19%\n",
    "  - BAFromZeroToDataAw is slow (50% of total time) because of (in order):\n",
    "    - pandas init (dict)\n",
    "    - baincrementnonspatial\n",
    "    - pandas setting\n",
    "    \n",
    "- parallel (3 cores) gets us to 2 - 6 days - save for last\n",
    "- AWS with 36 cores gets us to 4 - 12 hours ($6.70 - $20.10 USD on a c4.8xlarge instance in US West Region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     7191    2.670    0.000   40.459    0.006 GYPSYNonSpatial.py:959(BAfromZeroToDataAw)\r\n",
      "      444    0.172    0.000    4.115    0.009 GYPSYNonSpatial.py:1207(BAfromZeroToDataSw)\r\n",
      "      207    0.087    0.000    2.845    0.014 GYPSYNonSpatial.py:1340(BAfromZeroToDataPl)\r\n",
      "       10    0.012    0.001    1.711    0.171 GYPSYNonSpatial.py:1077(BAfromZeroToDataSb)\r\n"
     ]
    }
   ],
   "source": [
    "!cat forward-sim-1.txt | grep -i fromzero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify some means of optimization\n",
    "\n",
    "In order of priority/time taken\n",
    "\n",
    "1. pandas init dict\n",
    "    - `basal_area_aw_df = pd.DataFrame(columns=['BA_Aw'], index=xrange(max_age))`\n",
    "    - find a faster way to create this data frame\n",
    "    - relax the tolerance for aspen\n",
    "2. pandas set item\n",
    "    - use at method \n",
    "    - http://pandas.pydata.org/pandas-docs/stable/indexing.html#fast-scalar-value-getting-and-setting\n",
    "3. lambdas\n",
    "    - use cython for the gross tot vol and merch vol functions\n",
    "    - might be wise to refactor these first to have conventional names, keyword arguments, and a base implementation to get rid of the boilerplate\n",
    "    - don't be deceived - the callable is a miniscule portion; series.__getitem__ is taking most of the time\n",
    "    - again, using .at here would probably be a significant improvement\n",
    "4. basalareaincremementnonspatialaw\n",
    "    - this is actually slow because of the number of times the BAFromZeroToDataAw function is called as shown above\n",
    "    - relaxing the tolerance may help\n",
    "    - indeed the tolerance is 0.01 * some value while the other factor finder functions have 0.1 tolerance i think\n",
    "    - can also use cython for the increment functions\n",
    "\n",
    "do a profiling run with IO (of reading input data and writing the plot curves to files) in next run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
