{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap\n",
    "\n",
    "In order of priority/time taken\n",
    "\n",
    "1. basalareaincremementnonspatialaw\n",
    "    - this is actually slow because of the number of times the BAFromZeroToDataAw function is called as shown above\n",
    "    - relaxing the tolerance may help\n",
    "    - indeed the tolerance is 0.01 * some value while the other factor finder functions have 0.1 tolerance i think\n",
    "    - can also use cython for the increment functions\n",
    "2. vectorize merch and gross volume functions\n",
    "    - they require a lot of getting scalars off data frame, which is quite slow. faster to get an array\n",
    "\n",
    "do a profiling run with IO (of reading input data and writing the plot curves to files) in next run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decide on the action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- speed up increment functions\n",
    "    - use cython for increment functions\n",
    "    - it turns out this may not help that much. the function is pretty fast, it's called almost 500,000 times on the sample of 300 plots\n",
    "    - reduce the number of times its called maybe by using gradient descent for the optimization?\n",
    "    - relax the tolerance\n",
    "    - gives a context to refactor them as well (into their own module) which would be a welcome change\n",
    "    - the increment functions use numpy functions but operate on scalars, there is no benefit to using numpy functions there\n",
    "- performance-wise, it is not clear that this will pay off so much. vectorizing the volume functions is probably wiser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characterize what is happening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original gross volume function checks that top height is greater than 0\n",
    "\n",
    "\n",
    "``` python\n",
    "def GrossTotalVolume_Pl(BA_Pl, topHeight_Pl):\n",
    "    Tvol_Pl = 0\n",
    "\n",
    "    if topHeight_Pl > 0:\n",
    "        a1 = 0.194086\n",
    "        a2 = 0.988276\n",
    "        a3 = 0.949346\n",
    "        a4 = -3.39036\n",
    "        Tvol_Pl = a1* (BA_Pl**a2) * (topHeight_Pl **a3) * numpy.exp(1+(a4/((topHeight_Pl**2)+1)))\n",
    "\n",
    "    return Tvol_Pl\n",
    "```\n",
    "\n",
    "This makes it fail if trying to use it on an array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-10d9c5a07a68>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mGrossTotalVolume_Pl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/gypsy/gypsy/GYPSYNonSpatial.py\u001b[0m in \u001b[0;36mGrossTotalVolume_Pl\u001b[0;34m(BA_Pl, topHeight_Pl)\u001b[0m\n\u001b[1;32m   1453\u001b[0m     \u001b[0mTvol_Pl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1455\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtopHeight_Pl\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1456\u001b[0m         \u001b[0ma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.194086\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1457\u001b[0m         \u001b[0ma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.988276\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "from gypsy.GYPSYNonSpatial import GrossTotalVolume_Pl\n",
    "\n",
    "\n",
    "GrossTotalVolume_Pl(np.random.random(10) * 100, np.random.random(10) * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MWEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we can rewrite it to handle 0s properly, i.e. to return 0 where an input is 0, then it is trivial to vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44.1908473047\n",
      "0.0\n",
      "0.0\n",
      "[  415.44083176  3769.55471466  1288.45549553    49.77278285   298.91564963\n",
      "  1367.74822794   729.29619243   906.68358934  2393.18506461   385.18108024]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "def GrossTotalVolume_Pl_arr(BA_Pl, topHeight_Pl):\n",
    "    a1 = 0.194086\n",
    "    a2 = 0.988276\n",
    "    a3 = 0.949346\n",
    "    a4 = -3.39036\n",
    "    Tvol_Pl = a1* (BA_Pl**a2) * (topHeight_Pl **a3) * np.exp(1+(a4/((topHeight_Pl**2)+1)))\n",
    "\n",
    "    return Tvol_Pl\n",
    "\n",
    "print(GrossTotalVolume_Pl_arr(10, 10))\n",
    "print(GrossTotalVolume_Pl_arr(0, 10))\n",
    "print(GrossTotalVolume_Pl_arr(10, 0))\n",
    "print(GrossTotalVolume_Pl_arr(np.random.random(10) * 100, np.random.random(10) * 100))\n",
    "print(GrossTotalVolume_Pl_arr(np.zeros(10) * 100, np.random.random(10) * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ba = np.random.random(1000) * 100\n",
    "top_height = np.random.random(1000) * 100\n",
    "d = pd.DataFrame({'ba': ba, 'th': top_height})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 31.9 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "d.apply(\n",
    "    lambda x: GrossTotalVolume_Pl(\n",
    "        x.at['ba'],\n",
    "        x.at['th']\n",
    "    ),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 loops, best of 3: 165 Âµs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "GrossTotalVolume_Pl_arr(ba, top_height)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The array method is 20x faster. This is worth implementing. We should also add tests to help be explicity about the behaviour of these volume functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revise the code\n",
    "\n",
    "Go on. Do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests\n",
    "\n",
    "Do tests still pass?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review code changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "git log --since \"2016-11-14 19:30\" --oneline # 19:30 GMT/UTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "! git diff \"HEAD~$(git log --since \"2016-11-14 19:30\" --oneline | wc -l)\" ../gypsy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run timings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From last time:\n",
    "\n",
    "```\n",
    "real\t6m16.021s\n",
    "user\t5m59.620s\n",
    "sys  \t0m2.030s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After cython'ing iter functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# git checkout 4c978aff110001efdc917ed60cb611139e1b54c9 -b remove-getitem-redundancy\n",
    "# time gypsy simulate ../private-data/prepped_random_sample_300.csv --output-dir tmp\n",
    "# rm -rfd tmp\n",
    "\n",
    "# real\t5m36.407s\n",
    "# user\t5m25.740s\n",
    "# sys\t0m2.140s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "???"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gypsy.forward_simulation import simulate_forwards_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../private-data/prepped_random_sample_300.csv', index_col=0, nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "*** Profile stats marshalled to file u'forward-sim-2.prof'. \n",
      "\n",
      "*** Profile printout saved to text file u'forward-sim-2.txt'. \n"
     ]
    }
   ],
   "source": [
    "%%prun -D forward-sim-2.prof -T forward-sim-2.txt -q\n",
    "result = simulate_forwards_df(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         4167146 function calls (4034230 primitive calls) in 36.370 seconds\r\n",
      "\r\n",
      "   Ordered by: internal time\r\n",
      "\r\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n",
      "   492069    7.050    0.000    7.050    0.000 GYPSYNonSpatial.py:428(BasalAreaIncrementNonSpatialAw)\r\n",
      "     7191    2.481    0.000    9.716    0.001 GYPSYNonSpatial.py:956(BAfromZeroToDataAw)\r\n",
      "    90290    2.419    0.000    8.879    0.000 base.py:2116(get_value)\r\n",
      "    90280    1.686    0.000   17.526    0.000 indexing.py:1654(__getitem__)\r\n",
      "   369310    1.517    0.000    2.398    0.000 {isinstance}\r\n"
     ]
    }
   ],
   "source": [
    "!head forward-sim-2.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare performance visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use either of these commands to visualize the profiling\n",
    "\n",
    "```\n",
    "pyprof2calltree -k -i forward-sim-1.prof forward-sim-1.txt\n",
    "\n",
    "# or\n",
    "\n",
    "dc run --service-ports snakeviz notebooks/forward-sim-1.prof\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![definitive reference profile screenshot](forward-sim-1-performance-icicle.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### New"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![2nd iteration performance](forward-sim-2a-performance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of performance improvements\n",
    "\n",
    "forward_simulation is now 2x faster than last iteration, 8 times in total, due to the changes outlined in the code review section above\n",
    "\n",
    "on my hardware, this takes 1000 plots to ~4 minutes\n",
    "\n",
    "on carol's hardware, this takes 1000 plots to ~13 minutes\n",
    "\n",
    "For 1 million plots, we're looking at 2 to 9 days on desktop hardware\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profile with I/O\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! rm -rfd gypsy-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dir = 'gypsy-output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "*** Profile stats marshalled to file u'forward-sim-1.prof'. \n",
      "\n",
      "*** Profile printout saved to text file u'forward-sim-1.txt'. \n"
     ]
    }
   ],
   "source": [
    "%%prun -D forward-sim-2.prof -T forward-sim-2.txt -q\n",
    "# restart the kernel first\n",
    "data = pd.read_csv('../private-data/prepped_random_sample_300.csv', index_col=0, nrows=10)\n",
    "result = simulate_forwards_df(data)\n",
    "os.makedirs(output_dir)\n",
    "for plot_id, df in result.items():\n",
    "    filename = '%s.csv' % plot_id\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    df.to_csv(output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify new areas to optimize\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- from last time:\n",
    "    - parallel (3 cores) gets us to 2 - 6 days - save for last\n",
    "    - AWS with 36 cores gets us to 4 - 12 hours ($6.70 - $20.10 USD on a c4.8xlarge instance in US West Region)\n",
    "    - aws lambda and split up the data \n",
    "- now:\n",
    "    - getting items in apply is still slow - vectorize the functions\n",
    "    - cython for icnrement functions epsecially bA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
