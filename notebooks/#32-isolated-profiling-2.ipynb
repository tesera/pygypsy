{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap\n",
    "\n",
    "In order of priority/time taken\n",
    "\n",
    "1. pandas init dict\n",
    "    - `basal_area_aw_df = pd.DataFrame(columns=['BA_Aw'], index=xrange(max_age))`\n",
    "    - find a faster way to create this data frame\n",
    "    - relax the tolerance for aspen\n",
    "2. pandas set item\n",
    "    - use at method \n",
    "    - http://pandas.pydata.org/pandas-docs/stable/indexing.html#fast-scalar-value-getting-and-setting\n",
    "3. lambdas\n",
    "    - use cython for the gross tot vol and merch vol functions\n",
    "    - might be wise to refactor these first to have conventional names, keyword arguments, and a base implementation to get rid of the boilerplate\n",
    "    - don't be deceived - the callable is a miniscule portion; series.__getitem__ is taking most of the time\n",
    "    - again, using .at here would probably be a significant improvement\n",
    "4. basalareaincremementnonspatialaw\n",
    "    - this is actually slow because of the number of times the BAFromZeroToDataAw function is called as shown above\n",
    "    - relaxing the tolerance may help\n",
    "    - indeed the tolerance is 0.01 * some value while the other factor finder functions have 0.1 tolerance i think\n",
    "    - can also use cython for the increment functions\n",
    "\n",
    "do a profiling run with IO (of reading input data and writing the plot curves to files) in next run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characterize what is happening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing with df[] or series[] is slow for scalars (lambdas, pandas set)\n",
    "basalareaincrement is running a lot for aw, use the same tolerance as is used for other species\n",
    "\n",
    "merchvol, increment, and gross vol functions use pure python. cython would be effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decide on the action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- use same tolerance for aw as other species\n",
    "- use at instead of [] or ix? - compare these in MWE\n",
    "- creating data frame is slow, maybe because its fromdict. see if this can be improved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MWEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init from dict and xrange index vs from somethign else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 38.51 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000 loops, best of 3: 368 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "d = pd.DataFrame(columns=['A'], index=xrange(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.03 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000 loops, best of 3: 418 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "d = pd.DataFrame(columns=['A'], index=xrange(1000), dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 5.08 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000 loops, best of 3: 275 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "d = pd.DataFrame({'A': np.zeros(1000)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem here is that dataframe init being called 7000 times because of the aw ba factor finder\n",
    "\n",
    "Maybe it's not worth using a data frame here. use a list or numpy and then convert to dataframe when the factor is found, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 2.13 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for _ in xrange(5000):\n",
    "    d = pd.DataFrame(columns=['A'], index=xrange(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 14.1 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for _ in xrange(5000):\n",
    "    d = np.zeros(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review the code to see how this can be applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numpy/purepython approach as potential\n",
    "\n",
    "But there's a couple issues for which the code must be examined\n",
    "\n",
    "The problem comes from the following call chain\n",
    "\n",
    "`simulate_forwards_df` (called 1x) ->  \n",
    "`get_factors_for_all_species` (called 10x, 1x per plot) ->  \n",
    "`BAfactorFinder_Aw` (called 2x, 1x per plot that has aw) ->  \n",
    "`BAfromZeroToDataAw` (called 7191 times, most of which in this chain) ->   \n",
    "`DataFrame.__init__` (called 7932 times, most of which in this chain) ...  \n",
    "\n",
    "why does `BAfromZeroToDataAw` create a dataframe? It's good to see the code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, `simulate_forwards_df` calls `get_factors_for_all_species` and then `BAfromZeroToDataAw` with some parameters and simulation choice of false\n",
    "\n",
    "Note that when `simulation==False`, that is the only time that the list is created. otherwise the list is left empty.\n",
    "\n",
    "Note also that `simulation_choice` defaults to `True` in forward simulation, i.e. for when `BAfromZeroToData__` are called from forward simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "def simulate_forwards_df(plot_df, simulation_choice='yes'):\n",
    "    # ...\n",
    "    for row in plot_df:\n",
    "    # ...\n",
    "    \n",
    "            species_factors = get_factors_for_all_species(\n",
    "            startTage=startTage,\n",
    "            startTageAw=startTageAw,\n",
    "            # ...\n",
    "            )\n",
    "    # ...\n",
    "        BA_0_to_data_Aw = BAfromZeroToDataAw(\n",
    "            startTage, SI_bh_Aw, N0_Aw, BA_Aw0, SDF_Aw0, f_Aw, densities, simulation_choice='no', simulation=False\n",
    "            )\n",
    "        BA_0_to_data_Sb = BAfromZeroToDataSb(\n",
    "            startTage, startTageSb, y2bh_Sb, SC_Sb, SI_bh_Sb, N_bh_SbT, \n",
    "            N0_Sb, BA_Sb0, f_Sb, simulation_choice, simulation=False\n",
    "            )\n",
    "        BA_0_to_data_Sw = BAfromZeroToDataSw(\n",
    "            startTage, startTageSw, y2bh_Sw, SC_Sw, SI_bh_Sw, N_bh_SwT, \n",
    "            N0_Sw, SDF_Aw0, SDF_Pl0, SDF_Sb0, BA_Sw0, f_Sw, simulation_choice, simulation=False\n",
    "            )\n",
    "        BA_0_to_data_Pl = BAfromZeroToDataPl(\n",
    "            startTage, startTagePl, y2bh_Pl, SC_Pl, SI_bh_Pl, N_bh_PlT, \n",
    "            N0_Pl, SDF_Aw0, SDF_Sw0, SDF_Sb0, BA_Pl0, f_Pl, simulation_choice, simulation=False\n",
    "            )\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_factors_for_all_species` calls factor finder functions for each species, if the species is present, and returns a dict of the factors\n",
    "\n",
    "`BAfactorFinder_Aw` is the main suspect, for sime reason aspen has a harder time converging, so the loop in this function runs many times\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "def BAfactorFinder_Aw(**kwargs):\n",
    "    startTage = kwargs['startTage']\n",
    "    # ...\n",
    "    simulation_choice = 'yes'\n",
    "    f_Aw = 100\n",
    "    f_AwP1 = 100 * f_Aw\n",
    "    acceptableDiff = 0.01 * BA_AwT\n",
    "    BADiffFlag = False\n",
    "    iterCount = 0\n",
    "\n",
    "    while BADiffFlag == False:\n",
    "        BA_AwB = BAfromZeroToDataAw(startTage, SI_bh_Aw, N0_Aw,\n",
    "                                    BA_Aw0, SDF_Aw0, f_Aw, densities,\n",
    "                                    simulation_choice, simulation=True)[0]\n",
    "\n",
    "        if abs(BA_AwT - BA_AwB) < acceptableDiff:\n",
    "            BADiffFlag = True\n",
    "        else:\n",
    "            if (BA_AwT - BA_AwB) < 0:\n",
    "                f_AwP1 = f_Aw\n",
    "                f_AwP = f_Aw  *  (1+(numpy.log10(BA_AwT) - numpy.log10(abs(BA_AwB)))/ (100*numpy.log10(abs(BA_AwB))))\n",
    "                f_Aw = (f_AwP+f_Aw)/2\n",
    "            elif (BA_AwT - BA_AwB) > 0:\n",
    "                f_AwN = f_Aw * (1+(numpy.log10(BA_AwT) + numpy.log10(abs(BA_AwB)))/ (100* numpy.log10(abs(BA_AwB))))\n",
    "                f_Aw = (f_Aw+f_AwP1)/2\n",
    "\n",
    "        iterCount = iterCount + 1\n",
    "\n",
    "        if iterCount == 10000:\n",
    "            logger.warning(('GYPSYNonSpatial.BAfactorFinder_Aw()'\n",
    "                 ' Slow convergence with Basal Area: %s'\n",
    "                 ' and factor:%s '), BA_AwB, f_Aw)\n",
    "            return f_Aw\n",
    "    return f_Aw\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It calls `BAfromZeroToDataAw` with `simulation_choice` of `'yes'` and `simulation=True` **BUT IT ONLY USES THE 1ST RETURN VALUE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "factor finder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "``` python\n",
    "def BAfromZeroToDataAw(startTage, SI_bh_Aw, N0_Aw, BA_Aw0, SDF_Aw0, f_Aw,\n",
    "                       densities, simulation_choice, simulation=True):\n",
    "    logger.debug('getting basal area from time zero to time of data for aspen')\n",
    "\n",
    "    if simulation_choice == 'yes':\n",
    "        max_age = startTage\n",
    "    elif simulation_choice == 'no':\n",
    "        max_age = 250\n",
    "\n",
    "    basal_area_aw_df = pd.DataFrame(columns=['BA_Aw'], index=xrange(max_age))\n",
    "    BA_tempAw = BA_Aw0\n",
    "\n",
    "    for i, SC_Dict in enumerate(densities[0: max_age]):\n",
    "        bhage_Aw = SC_Dict['bhage_Aw']\n",
    "        SC_Aw = SC_Dict['SC_Aw']\n",
    "        N_bh_AwT = SC_Dict['N_bh_AwT']\n",
    "\n",
    "        if N0_Aw > 0:\n",
    "            if bhage_Aw < 0:\n",
    "                BA_AwB = 0\n",
    "            if bhage_Aw > 0:\n",
    "                SC_Aw = (SC_Aw) * f_Aw\n",
    "                BAinc_Aw = BasalAreaIncrementNonSpatialAw('Aw', SC_Aw, SI_bh_Aw, N_bh_AwT,\n",
    "                                                          N0_Aw, bhage_Aw, BA_tempAw)\n",
    "                BA_tempAw = BA_tempAw + BAinc_Aw\n",
    "                BA_AwB = BA_tempAw\n",
    "                if BA_AwB < 0:\n",
    "                    BA_AwB = 0\n",
    "            else:\n",
    "                BA_AwB = 0\n",
    "        else:\n",
    "            BA_tempAw = 0\n",
    "            BA_AwB = 0\n",
    "\n",
    "        # we might be able to remove this, always update this data frame, then we don't have to call\n",
    "        # bafromzerotodata again in forward_simulation using the newly found factor\n",
    "        if simulation == False:\n",
    "            basal_area_aw_df.loc[i, 'BA_Aw'] = BA_AwB\n",
    "\n",
    "    return BA_AwB, basal_area_aw_df\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revise the code\n",
    "\n",
    "Go on. Do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review code changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# git log --since 2016-11-09 --oneline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ! git diff HEAD~7 ../gypsy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests\n",
    "\n",
    "Do tests still pass?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/gypsy/venv/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "from gypsy.forward_simulation import simulate_forwards_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../private-data/prepped_random_sample_300.csv', index_col=0, nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "*** Profile stats marshalled to file u'forward-sim-1.prof'. \n",
      "\n",
      "*** Profile printout saved to text file u'forward-sim-1.txt'. \n"
     ]
    }
   ],
   "source": [
    "%%prun -D forward-sim-2.prof -T forward-sim-2.txt -q\n",
    "result = simulate_forwards_df(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         10055657 function calls (9875729 primitive calls) in 76.264 seconds\r\n",
      "\r\n",
      "   Ordered by: internal time\r\n",
      "\r\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n",
      "   492069    6.857    0.000    6.857    0.000 GYPSYNonSpatial.py:427(BasalAreaIncrementNonSpatialAw)\r\n",
      "  1836602    6.527    0.000    9.190    0.000 {isinstance}\r\n",
      "796652/624746    3.102    0.000    4.823    0.000 {len}\r\n",
      "     7191    2.670    0.000   40.459    0.006 GYPSYNonSpatial.py:959(BAfromZeroToDataAw)\r\n",
      "   511948    2.020    0.000    3.373    0.000 {getattr}\r\n"
     ]
    }
   ],
   "source": [
    "!head forward-sim-2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff: forward-sim.txt: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!diff -y forward-sim-2.txt forward-sim-1.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare performance visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use either of these commands to visualize the profiling\n",
    "\n",
    "```\n",
    "pyprof2calltree -k -i forward-sim-1.prof forward-sim-1.txt\n",
    "\n",
    "# or\n",
    "\n",
    "dc run --service-ports snakeviz notebooks/forward-sim-1.prof\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![definitive reference profile screenshot](forward-sim-1-performance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### New"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1st iteration performance](forward-sim-2-performance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of performance improvements\n",
    "\n",
    "forward_simulation is now 4x faster due to the changes outlined in the code review section above\n",
    "\n",
    "on my hardware, this takes 1000 plots to ~8 minutes\n",
    "\n",
    "on carol's hardware, this takes 1000 plots to ~25 minutes\n",
    "\n",
    "For 1 million plots, we're looking at 5 to 17 days on desktop hardware\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profile with I/O\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! rm -rfd gypsy-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dir = 'gypsy-output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "*** Profile stats marshalled to file u'forward-sim-1.prof'. \n",
      "\n",
      "*** Profile printout saved to text file u'forward-sim-1.txt'. \n"
     ]
    }
   ],
   "source": [
    "%%prun -D forward-sim-2.prof -T forward-sim-2.txt -q\n",
    "# restart the kernel first\n",
    "data = pd.read_csv('../private-data/prepped_random_sample_300.csv', index_col=0, nrows=10)\n",
    "result = simulate_forwards_df(data)\n",
    "os.makedirs(output_dir)\n",
    "for plot_id, df in result.items():\n",
    "    filename = '%s.csv' % plot_id\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    df.to_csv(output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify new areas to optimize\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- from last time:\n",
    "    - parallel (3 cores) gets us to 2 - 6 days - save for last\n",
    "    - AWS with 36 cores gets us to 4 - 12 hours ($6.70 - $20.10 USD on a c4.8xlarge instance in US West Region)\n",
    "- now:\n",
    "    - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify some means of optimization\n",
    "\n",
    "In order of priority/time taken\n",
    "\n",
    "1.\n",
    "2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
