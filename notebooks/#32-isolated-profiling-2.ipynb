{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap\n",
    "\n",
    "In order of priority/time taken\n",
    "\n",
    "1. pandas init dict\n",
    "    - `basal_area_aw_df = pd.DataFrame(columns=['BA_Aw'], index=xrange(max_age))`\n",
    "    - find a faster way to create this data frame\n",
    "    - relax the tolerance for aspen\n",
    "2. pandas set item\n",
    "    - use at method \n",
    "    - http://pandas.pydata.org/pandas-docs/stable/indexing.html#fast-scalar-value-getting-and-setting\n",
    "3. lambdas\n",
    "    - use cython for the gross tot vol and merch vol functions\n",
    "    - might be wise to refactor these first to have conventional names, keyword arguments, and a base implementation to get rid of the boilerplate\n",
    "    - don't be deceived - the callable is a miniscule portion; series.__getitem__ is taking most of the time\n",
    "    - again, using .at here would probably be a significant improvement\n",
    "4. basalareaincremementnonspatialaw\n",
    "    - this is actually slow because of the number of times the BAFromZeroToDataAw function is called as shown above\n",
    "    - relaxing the tolerance may help\n",
    "    - indeed the tolerance is 0.01 * some value while the other factor finder functions have 0.1 tolerance i think\n",
    "    - can also use cython for the increment functions\n",
    "\n",
    "do a profiling run with IO (of reading input data and writing the plot curves to files) in next run\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Characterize what is happening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indexing with df[] or series[] is slow for scalars (lambdas, pandas set)\n",
    "basalareaincrement is running a lot for aw, use the same tolerance as is used for other species\n",
    "\n",
    "merchvol, increment, and gross vol functions use pure python. cython would be effective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decide on the action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- use same tolerance for aw as other species\n",
    "- use at instead of [] or ix? - compare these in MWE\n",
    "- creating data frame is slow, maybe because its fromdict. see if this can be improved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MWEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## init from dict and xrange index vs from somethign else"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 38.51 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000 loops, best of 3: 368 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "d = pd.DataFrame(columns=['A'], index=xrange(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 4.03 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000 loops, best of 3: 418 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "d = pd.DataFrame(columns=['A'], index=xrange(1000), dtype='float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 5.08 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "1000 loops, best of 3: 275 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "d = pd.DataFrame({'A': np.zeros(1000)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem here is that dataframe init being called 7000 times because of the aw ba factor finder\n",
    "\n",
    "Maybe it's not worth using a data frame here. use a list or numpy and then convert to dataframe when the factor is found, e.g.:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 2.13 s per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for _ in xrange(5000):\n",
    "    d = pd.DataFrame(columns=['A'], index=xrange(1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 14.1 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "for _ in xrange(5000):\n",
    "    d = np.zeros(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review the code to see how this can be applied"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The numpy/purepython approach as potential\n",
    "\n",
    "But there's a couple issues for which the code must be examined\n",
    "\n",
    "The problem comes from the following call chain\n",
    "\n",
    "`simulate_forwards_df` (called 1x) ->  \n",
    "`get_factors_for_all_species` (called 10x, 1x per plot) ->  \n",
    "`BAfactorFinder_Aw` (called 2x, 1x per plot that has aw) ->  \n",
    "`BAfromZeroToDataAw` (called 7191 times, most of which in this chain) ->   \n",
    "`DataFrame.__init__` (called 7932 times, most of which in this chain) ...  \n",
    "\n",
    "why does `BAfromZeroToDataAw` create a dataframe? It's good to see the code:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, `simulate_forwards_df` calls `get_factors_for_all_species` and then `BAfromZeroToDataAw` with some parameters and simulation choice of false\n",
    "\n",
    "Note that when `simulation==False`, that is the only time that the list is created. otherwise the list is left empty.\n",
    "\n",
    "Note also that `simulation_choice` defaults to `True` in forward simulation, i.e. for when `BAfromZeroToData__` are called from forward simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_factors_for_all_species` calls factor finder functions for each species, if the species is present, and returns a dict of the factors\n",
    "\n",
    "`BAfactorFinder_Aw` is the main suspect, for sime reason aspen has a harder time converging, so the loop in this function runs many times\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It calls `BAfromZeroToDataAw` with `simulation_choice` of `'yes'` and `simulation=True` **BUT IT ONLY USES THE 1ST RETURN VALUE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Revise the code\n",
    "\n",
    "Go on. Do it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review code changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# git log --since 2016-11-09 --oneline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ! git diff HEAD~7 ../gypsy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests\n",
    "\n",
    "Do tests still pass?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run timings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# after factoring dataframe out of zerotodata functions\n",
    "# git checkout dev\n",
    "# time gypsy simulate ../private-data/prepped_random_sample_300.csv --output-dir tmp\n",
    "# rm -rfd tmp\n",
    "\n",
    "# real\t20m56.499s\n",
    "# user\t17m1.070s\n",
    "# sys\t0m43.240s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# after factoring dataframe out of zerotodata functions\n",
    "# git checkout -b da080a79200f50d2dda7942c838b7f3cad845280 df-factored-out-zerotodata\n",
    "# time gypsy simulate ../private-data/prepped_random_sample_300.csv --output-dir tmp\n",
    "# rm -rfd tmp\n",
    "\n",
    "# real\t5m51.028s\n",
    "# user\t5m40.130s\n",
    "# sys\t0m1.680s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the data frame init gets a 25% time reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# after factoring dataframe out of zerotodata functions\n",
    "# git checkout -b da080a79200f50d2dda7942c838b7f3cad845280 df-factored-out-zerotodata\n",
    "# time gypsy simulate ../private-data/prepped_random_sample_300.csv --output-dir tmp\n",
    "# rm -rfd tmp\n",
    "\n",
    "# real\t5m51.028s\n",
    "# user\t5m40.130s\n",
    "# sys\t0m1.680s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/gypsy/venv/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "from gypsy.forward_simulation import simulate_forwards_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../private-data/prepped_random_sample_300.csv', index_col=0, nrows=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "*** Profile stats marshalled to file u'forward-sim-1.prof'. \n",
      "\n",
      "*** Profile printout saved to text file u'forward-sim-1.txt'. \n"
     ]
    }
   ],
   "source": [
    "%%prun -D forward-sim-2.prof -T forward-sim-2.txt -q\n",
    "result = simulate_forwards_df(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         10055657 function calls (9875729 primitive calls) in 76.264 seconds\r\n",
      "\r\n",
      "   Ordered by: internal time\r\n",
      "\r\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\r\n",
      "   492069    6.857    0.000    6.857    0.000 GYPSYNonSpatial.py:427(BasalAreaIncrementNonSpatialAw)\r\n",
      "  1836602    6.527    0.000    9.190    0.000 {isinstance}\r\n",
      "796652/624746    3.102    0.000    4.823    0.000 {len}\r\n",
      "     7191    2.670    0.000   40.459    0.006 GYPSYNonSpatial.py:959(BAfromZeroToDataAw)\r\n",
      "   511948    2.020    0.000    3.373    0.000 {getattr}\r\n"
     ]
    }
   ],
   "source": [
    "!head forward-sim-2.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diff: forward-sim.txt: No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!diff -y forward-sim-2.txt forward-sim-1.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare performance visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use either of these commands to visualize the profiling\n",
    "\n",
    "```\n",
    "pyprof2calltree -k -i forward-sim-1.prof forward-sim-1.txt\n",
    "\n",
    "# or\n",
    "\n",
    "dc run --service-ports snakeviz notebooks/forward-sim-1.prof\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Old"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![definitive reference profile screenshot](forward-sim-1-performance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### New"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![1st iteration performance](forward-sim-2-performance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of performance improvements\n",
    "\n",
    "forward_simulation is now 4x faster due to the changes outlined in the code review section above\n",
    "\n",
    "on my hardware, this takes 1000 plots to ~8 minutes\n",
    "\n",
    "on carol's hardware, this takes 1000 plots to ~25 minutes\n",
    "\n",
    "For 1 million plots, we're looking at 5 to 17 days on desktop hardware\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Profile with I/O\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "! rm -rfd gypsy-output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output_dir = 'gypsy-output'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "*** Profile stats marshalled to file u'forward-sim-1.prof'. \n",
      "\n",
      "*** Profile printout saved to text file u'forward-sim-1.txt'. \n"
     ]
    }
   ],
   "source": [
    "%%prun -D forward-sim-2.prof -T forward-sim-2.txt -q\n",
    "# restart the kernel first\n",
    "data = pd.read_csv('../private-data/prepped_random_sample_300.csv', index_col=0, nrows=10)\n",
    "result = simulate_forwards_df(data)\n",
    "os.makedirs(output_dir)\n",
    "for plot_id, df in result.items():\n",
    "    filename = '%s.csv' % plot_id\n",
    "    output_path = os.path.join(output_dir, filename)\n",
    "    df.to_csv(output_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify new areas to optimize\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- from last time:\n",
    "    - parallel (3 cores) gets us to 2 - 6 days - save for last\n",
    "    - AWS with 36 cores gets us to 4 - 12 hours ($6.70 - $20.10 USD on a c4.8xlarge instance in US West Region)\n",
    "- now:\n",
    "    - "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify some means of optimization\n",
    "\n",
    "In order of priority/time taken\n",
    "\n",
    "1.\n",
    "2."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
